{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir(\"Labeled-Hindi-Corpus\")\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "references = \"[?.,]*\\[?[0१२३४५६७८९०][१२३४५६७८९०0]*\\]\"\n",
    "extras = \"[\\)\\(]\"\n",
    "eclipse = \"\\.+\"\n",
    "puncts = \"[,\\-']\"\n",
    "rep = [references, extras, puncts]\n",
    "rep_regex = '|'.join('%s' % val for val in rep)\n",
    "add_space = []\n",
    "sent_ends = [\"?\", \"!\", \".\", \"।\", \"|\"]\n",
    "add_space = [\"V_VB\", \"N_NN\", \"RD_PUNC\", \"JJ \", \"NNP\", \"N_NNP\"]\n",
    "def handle_sentends(tokens) :\n",
    "    n = len(tokens)\n",
    "    i = 0\n",
    "    while(i < n) :\n",
    "        token = tokens[i]\n",
    "        for end in sent_ends :\n",
    "            if end in token :\n",
    "                if(len(token) != 1):\n",
    "                    tokens[i] = token.replace(end, \"\") \n",
    "                    tokens.insert(i+1, end+\"_SENT\")\n",
    "                    n += 1\n",
    "                    i += 1\n",
    "                else :\n",
    "                    tokens[i] = end+\"_SENT\"\n",
    "        i += 1\n",
    "    return tokens\n",
    "def preprocess(sent) :\n",
    "    sent = re.sub(rep_regex, \"\", sent)\n",
    "    sent = sent.replace(\"<s>P\", \"<s>\")\n",
    "    sent = sent.replace(\"<s> P\", \"<s>\")\n",
    "    sent = sent.replace(\"</s>P\", \"</s>\")\n",
    "    sent = sent.replace(\"<\\s>\", \"</s>\")\n",
    "    sent = sent.replace(\"</s><s>\", \"</s> <s>\")\n",
    "    sent = sent.replace(\"|P\", \"\")\n",
    "    sent = sent.replace(\"aux\", \"AUX\")\n",
    "    sent = sent.replace(\" WQ\", \"_WQ\")\n",
    "    sent = sent.replace(\" QW\", \"_QW\")\n",
    "    sent = sent.replace(\" UT\", \"_UT \")\n",
    "    sent = sent.replace(\" XC\", \"_XC\")\n",
    "    sent = sent.replace(\" QF\", \"_QF\")\n",
    "    sent = sent.replace(\" DEM\", \"_DEM\")\n",
    "    sent = sent.replace(\" UT\", \"_UT\")\n",
    "    sent = sent.replace(\" QO\", \"_QO\")\n",
    "    sent = sent.replace(\" RDP\", \"_RDP\")\n",
    "    sent = sent.replace(\"SP\", \"_SP\")\n",
    "    sent = sent.replace(\"V_VAUX\", \"V_VAUX \")\n",
    "    sent = sent.replace(\"NST\", \"_NST\")\n",
    "    sent = sent.replace(\"fW\", \"FW\")\n",
    "    #sent = sent.replace(\"IN\", \"_IN\")\n",
    "    for tag in add_space :\n",
    "        sent = sent.replace(tag, tag+\" \")\n",
    "    if(sent[0:3] == \"<s>\") :\n",
    "        sent = \"<s> \"+sent[3:]\n",
    "    elif(sent[1:4] == \"<s>\") :\n",
    "        sent = \"<s> \"+sent[4:]\n",
    "    else :\n",
    "        sent = \"<s> \"+sent\n",
    "    if(sent[-5:-1] == \"</s>\") :\n",
    "        if(sent[-6] != \" \") :\n",
    "            sent = sent[:-5]+\" </s>\"\n",
    "    elif(sent[-4:] == \"</s>\") :\n",
    "        if(sent[-5] != \" \") :\n",
    "            sent = sent[:-4] +\" </s>\"\n",
    "    else :\n",
    "        sent = sent + \" </s>\"\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_and_tags(tokens) :\n",
    "    words = []\n",
    "    tags = []\n",
    "    for sent_tokens in tokens :\n",
    "        sent_words = []\n",
    "        sent_tags = []\n",
    "        for i in range(len(sent_tokens)) :\n",
    "            token = sent_tokens[i]\n",
    "            if(token.find(\"_\") != -1) :\n",
    "                pos = token.find(\"_\")\n",
    "                sent_words.append(token[:pos])\n",
    "                sent_tags.append(token[pos+1:])\n",
    "            elif(token == \"<s>\"):\n",
    "                sent_words.append(token)\n",
    "                sent_tags.append(\"START\")\n",
    "            elif(token == \"</s>\"):\n",
    "                sent_words.append(token)\n",
    "                sent_tags.append(\"END\")   \n",
    "            else :\n",
    "                sent_words.append(token)\n",
    "                sent_tags.append(\"UN\")\n",
    "        words.append(sent_words)\n",
    "        tags.append(sent_tags)\n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(n, tokens) :\n",
    "    ngrams = []\n",
    "    for token in tokens :\n",
    "        if(len(token) < n) :\n",
    "            continue\n",
    "        else :\n",
    "            i = 0\n",
    "            while(i < len(token)-n+1) :\n",
    "                ngrams.append(token[i:i+n])\n",
    "                i += 1\n",
    "    return ngrams\n",
    "\n",
    "def get_freq_dict(ngrams) :\n",
    "    ngram_freq = {}\n",
    "    for ngram in ngrams :\n",
    "        key = ' '.join([str(elem) for elem in ngram])\n",
    "        if key not in ngram_freq :\n",
    "            ngram_freq[key] = 1\n",
    "        else :\n",
    "            ngram_freq[key] += 1\n",
    "    return ngram_freq\n",
    "\n",
    "def write_to_file(ngrams, fname) :\n",
    "    f = open(fname, \"w\")\n",
    "    to_write = \"\"\n",
    "    for terms in ngrams :\n",
    "        for term in terms :\n",
    "            to_write += (term+\" \")\n",
    "        to_write = to_write[:-1]\n",
    "        to_write += \"\\n\"\n",
    "    f.write(to_write)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PR_PRPRF', 'WDT', 'PR_PRP_PR_PRP_N_NN', 'PDT', 'QC', 'JJ_JJ', 'VBZ', 'QTC', 'FW_FW', 'NNN', 'DMI', 'WQ', 'RB_RBR', 'P', 'NN', 'V_VB', 'DM_DMQ', 'RDF', 'RD_ECH', 'UN', 'SP', 'QT_QTF', 'UH', 'RB_JJ', 'RB_N_NN', 'QTO', 'CC_CCD', 'NEG', '_RB', 'XC_XC_N_NN', 'P_SP_RD_SYM', 'QTF', 'CC_CCS', 'IN_IN', 'PR_PRP', 'END', 'QT_QTC', 'PR_PRL', '_NST', 'DM_DMI', 'QF', 'PRC', 'P_SP', 'NST', 'JJ_N_NN', 'CD', 'RD_SYM', 'SENT', 'JJ_JJ_N_NN', 'N_NEG', 'CCD', 'RB', 'V_VM_RD_PUNC', 'PR_PRQ', 'JJ_JJR', '_QT_QTF', 'QT_QTO', 'RP_INTF', 'RP_NEG', 'XC', 'V_VV', 'DM_DMR', 'JJ', 'DT', 'RP_NEG_RP_NEG_N_NN', 'RD_UNK_RD_UNK_N_NN', 'PRP', 'PR_PRP_DM_N_NN', 'Q_QT', 'PR_PRF', 'CC_CC_N_NN', 'SYM', 'N__NST', 'DMQ', 'VB', 'INJ', 'PUNC', 'PRP$_PRP$', 'PRI', 'CCS', 'WDTUNC', 'QO', 'DEM', 'P_SP_P_SP_N_NN', 'V_VM', 'NNP', 'JJ_V_VAUX', 'RB_RBS', 'WP', 'RP', 'PRF', 'FW', 'DMD', 'IN_DT', 'V_VM_SYM', 'RB_RB', 'V_VM_V_VAUX', 'N_NN', 'ECH', 'RDP', 'DMR', 'PR_PRFRF', 'IN', 'V_VMG', 'QT_QTC_RD_SYM', 'SYSM', 'PRP$', 'PRQ', 'RD_PUNC', 'V_VAXU', 'QT', 'RD_UNK', 'RP_INTF_RP_INTF_N_NN', 'DM', 'PRPS', 'PR_PRC', 'PRP_RPD', 'RP_RPD', 'JJ_JJS', 'RP_RP_N_NN', 'START', 'V_VM_V_VM_N_NN', 'QCबार_RP', '_N_NN', 'RPD', 'INTF', 'RP_INJ', 'RP_NEGRF', 'DM_DMD', 'V_VAUX', 'JJ_RD_PUNC', 'CC'}\n"
     ]
    }
   ],
   "source": [
    "hindi_tokens = []\n",
    "for file in files:\n",
    "    name = file\n",
    "    file = \"Labeled-Hindi-Corpus/\"+file\n",
    "    f = open(file, \"r\")\n",
    "    sents = f.readlines()\n",
    "    for sent in sents :\n",
    "        sent = sent.strip()\n",
    "        sent = preprocess(sent)\n",
    "        hindi_tokens.append(handle_sentends(sent.split()))\n",
    "    f.close()  \n",
    "hindi_words, hindi_tags = get_words_and_tags(hindi_tokens)\n",
    "hindi_tags_list = [item for sublist in hindi_tags for item in sublist]\n",
    "print(set(hindi_tags_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexity_add(test_data, hindi_words, k, ngrams = 2) :\n",
    "    \n",
    "    test_tokens = []\n",
    "    for row in test_data :\n",
    "        test_tokens.extend(row)\n",
    "    V = len(set(test_tokens))\n",
    "    \n",
    "    test_ngrams = get_ngrams(ngrams, test_data)\n",
    "    N = len(test_ngrams)\n",
    "    \n",
    "    hindi_ngrams = get_ngrams(ngrams, hindi_words)\n",
    "    prev_grams = get_ngrams(ngrams-1, hindi_words)\n",
    "    \n",
    "    ngram_freq = get_freq_dict(hindi_ngrams)\n",
    "    prev_gram_freq = get_freq_dict(prev_grams)\n",
    "    #print(ngram_freq)\n",
    "    #print(prev_gram_freq)\n",
    "    prob = 1\n",
    "    for i in range(1, len(test_ngrams)) :\n",
    "        prev = \"\"\n",
    "        for j in range(len(test_ngrams[i])-1) :\n",
    "            prev += (test_ngrams[i][j]+\" \")\n",
    "        prev = prev[:-1]\n",
    "        ngram = ' '.join([str(elem) for elem in test_ngrams[i]])\n",
    "        \n",
    "        if ngram in ngram_freq :\n",
    "            if prev in prev_gram_freq:\n",
    "                #print(prev, \",\", ngram, \",\", prev_gram_freq[prev], ngram_freq[ngram])\n",
    "                #print((ngram_freq[ngram]+k)/((prev_gram_freq[prev])+k*V))\n",
    "                prob *= ((ngram_freq[ngram]+k)/((prev_gram_freq[prev])+k*V))\n",
    "            else :\n",
    "                #print(prev, \",\", ngram,\",\", 0, ngram_freq[ngram])\n",
    "                #print((ngram_freq[ngram]+k)/(k*V))\n",
    "                prob *= ((ngram_freq[ngram]+k)/(k*V))\n",
    "        else :\n",
    "            if prev in prev_gram_freq :\n",
    "                #print(prev, \",\", ngram, \",\", prev_gram_freq[prev], 0)\n",
    "                #print(k/((prev_gram_freq[prev])+k*V))\n",
    "                prob *= (k/((prev_gram_freq[prev])+k*V))\n",
    "            else :\n",
    "                #print(prev,\",\", ngram, \",\", 0, 0)\n",
    "                #print(1/V)\n",
    "                prob *= (1/V)\n",
    "        #print(prob)\n",
    "    print(prob)\n",
    "    print(N, V)\n",
    "    perp = 1/prob\n",
    "    perp = pow(perp, 1/N)\n",
    "    return perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'योजना', 'पूरे', 'देश', 'में', 'होगी', 'लागू', '</s>']\n",
      "0.0054869684499314125\n",
      "4 8\n",
      "Add_k: 3.6742346141747673\n",
      "['<s>', 'देश', 'लागू', 'में', 'होगी', 'पूरे', 'योजना', '</s>']\n",
      "2.2194602272727273e-05\n",
      "6 8\n",
      "Add_k: 5.9652059016524355\n"
     ]
    }
   ],
   "source": [
    "#f = open(\"test.txt\", \"r\")\n",
    "#sents = f.readlines()\n",
    "sents = [\"योजना पूरे देश में होगी लागू\", \"देश लागू में होगी पूरे योजना\"]\n",
    "test_tokens = []\n",
    "for sent in sents :\n",
    "    sent = sent.strip()\n",
    "    sent = preprocess(sent)\n",
    "    test_tokens.append(sent.split())\n",
    "print(test_tokens[0])\n",
    "perplexity = get_perplexity_add([test_tokens[0]], hindi_words, k=1, ngrams=5)\n",
    "print(\"Add_k: \"+str(perplexity))\n",
    "print(test_tokens[1])\n",
    "perplexity = get_perplexity_add([test_tokens[1]], hindi_words, k=1, ngrams=3)\n",
    "print(\"Add_k: \"+str(perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6276622759582344e-195\n",
      "105 74\n",
      "Add_k: 71.09074699075714\n",
      "5.587256197124121e-250\n",
      "135 74\n",
      "Add_k: 70.19675680052633\n"
     ]
    }
   ],
   "source": [
    "f = open(\"test.txt\", \"r\")\n",
    "test_tokens = []\n",
    "sents = f.readlines()\n",
    "for sent in sents :\n",
    "    sent = sent.strip()\n",
    "    sent = preprocess(sent)\n",
    "    test_tokens.append(sent.split())\n",
    "perplexity = get_perplexity_add(test_tokens, hindi_words, k=1, ngrams=5)\n",
    "print(\"Add_k: \"+str(perplexity))\n",
    "perplexity = get_perplexity_add(test_tokens, hindi_words, k=1, ngrams=2)\n",
    "print(\"Add_k: \"+str(perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
