{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"about_coep.txt\"\n",
    "doc2 = \"coep_cutoff.txt\"\n",
    "doc3 = \"placements.txt\"\n",
    "corpus = [doc1, doc2, doc3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation as punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "punctuation = \"[\"+punctuation+\"]\"\n",
    "\n",
    "#Remove punctuation \n",
    "def remove_punctuation(string) :\n",
    "    return(re.sub(punctuation, \"\", string))\n",
    "\n",
    "#Remove stopwords\n",
    "def remove_stopwords(tokens) :\n",
    "    without_stopwords = []\n",
    "    for token in tokens :\n",
    "        if token not in stopwords :\n",
    "            without_stopwords.append(token.lower())\n",
    "    return without_stopwords\n",
    "\n",
    "#Lemmatize\n",
    "def lemmatize(tokens) :\n",
    "    lemmas = []\n",
    "    pos = pos_tag(tokens)\n",
    "    for word, tag in pos :\n",
    "        tag_starting = tag[0].lower()\n",
    "        tag_starting = tag_starting if tag_starting in ['a', 'r', 'n', 'v'] else None\n",
    "        if not tag_starting :\n",
    "            lemma = word\n",
    "        else :\n",
    "            lemma = lemmatizer.lemmatize(word, tag_starting)\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['college', 'of', 'engineering', 'pune', 'coep', 'is', 'an', 'autonomous', 'institute', 'located', 'in', 'pune', 'maharashtra', 'india', 'and', 'was', 'established', 'in', 'the', 'year', '1854', 'established', 'in', '1854', 'it', 'is', 'one', 'of', 'the', 'oldest', 'engineering', 'colleges', 'in', 'india']\n",
      "['while', 'coep', 'cutoff', '2020', 'depends', 'on', 'entrance', 'exam', 'mht', 'cet', 'this', 'exam', 'is', 'conducted', 'by', 'dte', 'maharashtra', 'and', 'not', 'by', 'coep', 'for', 'ug', 'civil', 'engineering', 'coep', 'admission', 'cut', 'off', 'for', 'mhtcet', 'reservation', 'maharashtra', 'cutoff', 'by', 'score', 'obc', '163', 'st', '133', 'nt1', '87', 'sc', '147']\n",
      "['placements', 'from', '2020', 'batch', 'about', '50', 'of', 'the', 'students', 'got', 'placements', 'maximum', 'placements', 'are', 'conducted', 'for', 'a', 'computer', 'course', 'and', 'along', 'with', 'that', 'students', 'who', 'opt', 'for', 'computer', 'minor', 'have', 'great', 'opportunities', 'for', 'placements']\n"
     ]
    }
   ],
   "source": [
    "#Dictionary of document:[words]\n",
    "doc_terms = {}\n",
    "#Getting terms in each document(Removing spacing)\n",
    "for doc in corpus :\n",
    "    doc_terms[doc] = []\n",
    "    with open(\"corpus/\"+doc, 'r') as file :\n",
    "        for line in file :\n",
    "            line = remove_punctuation(line.lower())\n",
    "            doc_terms[doc].extend(line.split())\n",
    "    print(doc_terms[doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['college', 'engineering', 'pune', 'coep', 'autonomous', 'institute', 'locate', 'pune', 'maharashtra', 'india', 'establish', 'year', '1854', 'establish', '1854', 'one', 'oldest', 'engineering', 'college', 'india']\n",
      "['coep', 'cutoff', '2020', 'depend', 'entrance', 'exam', 'mht', 'cet', 'exam', 'conduct', 'dte', 'maharashtra', 'coep', 'ug', 'civil', 'engineering', 'coep', 'admission', 'cut', 'mhtcet', 'reservation', 'maharashtra', 'cutoff', 'score', 'obc', '163', 'st', '133', 'nt1', '87', 'sc', '147']\n",
      "['placement', '2020', 'batch', '50', 'student', 'get', 'placement', 'maximum', 'placement', 'conduct', 'computer', 'course', 'along', 'student', 'opt', 'computer', 'minor', 'great', 'opportunity', 'placement']\n"
     ]
    }
   ],
   "source": [
    "indexes = []\n",
    "for doc, terms in doc_terms.items() :\n",
    "    terms = remove_stopwords(terms)\n",
    "    #print(doc_terms[doc])\n",
    "    terms = lemmatize(terms)\n",
    "    doc_terms[doc] = terms\n",
    "    print(doc_terms[doc])\n",
    "    indexes.extend(terms) \n",
    "indexes = list(set(indexes))\n",
    "\n",
    "indexes_dict = {}\n",
    "for i in range(len(indexes)) :\n",
    "    indexes_dict[indexes[i]] = i\n",
    "    \n",
    "#print(len(indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term-Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             about_coep.txt  coep_cutoff.txt  placements.txt\n",
      "great                   0.0              0.0             1.0\n",
      "obc                     0.0              1.0             0.0\n",
      "147                     0.0              1.0             0.0\n",
      "2020                    0.0              1.0             1.0\n",
      "year                    1.0              0.0             0.0\n",
      "one                     1.0              0.0             0.0\n",
      "oldest                  1.0              0.0             0.0\n",
      "entrance                0.0              1.0             0.0\n",
      "exam                    0.0              2.0             0.0\n",
      "133                     0.0              1.0             0.0\n",
      "87                      0.0              1.0             0.0\n",
      "minor                   0.0              0.0             1.0\n",
      "college                 2.0              0.0             0.0\n",
      "opt                     0.0              0.0             1.0\n",
      "admission               0.0              1.0             0.0\n",
      "mht                     0.0              1.0             0.0\n",
      "sc                      0.0              1.0             0.0\n",
      "get                     0.0              0.0             1.0\n",
      "locate                  1.0              0.0             0.0\n",
      "ug                      0.0              1.0             0.0\n",
      "cut                     0.0              1.0             0.0\n",
      "maharashtra             1.0              2.0             0.0\n",
      "mhtcet                  0.0              1.0             0.0\n",
      "nt1                     0.0              1.0             0.0\n",
      "pune                    2.0              0.0             0.0\n",
      "maximum                 0.0              0.0             1.0\n",
      "course                  0.0              0.0             1.0\n",
      "opportunity             0.0              0.0             1.0\n",
      "cet                     0.0              1.0             0.0\n",
      "163                     0.0              1.0             0.0\n",
      "depend                  0.0              1.0             0.0\n",
      "engineering             2.0              1.0             0.0\n",
      "score                   0.0              1.0             0.0\n",
      "batch                   0.0              0.0             1.0\n",
      "computer                0.0              0.0             2.0\n",
      "reservation             0.0              1.0             0.0\n",
      "coep                    1.0              3.0             0.0\n",
      "india                   2.0              0.0             0.0\n",
      "1854                    2.0              0.0             0.0\n",
      "dte                     0.0              1.0             0.0\n",
      "civil                   0.0              1.0             0.0\n",
      "placement               0.0              0.0             4.0\n",
      "establish               2.0              0.0             0.0\n",
      "institute               1.0              0.0             0.0\n",
      "conduct                 0.0              1.0             1.0\n",
      "50                      0.0              0.0             1.0\n",
      "student                 0.0              0.0             2.0\n",
      "st                      0.0              1.0             0.0\n",
      "cutoff                  0.0              2.0             0.0\n",
      "autonomous              1.0              0.0             0.0\n",
      "along                   0.0              0.0             1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "term_document_matrix = np.zeros((len(indexes), len(doc_terms)))\n",
    "indexes = list(indexes)\n",
    "\n",
    "#Getting term frequencies\n",
    "for row in range(len(indexes)) :\n",
    "    for col in range(len(corpus)) :\n",
    "        term_document_matrix[row][col] = doc_terms[corpus[col]].count(indexes[row])\n",
    "\n",
    "cols = [corpus[i] for i in range(len(corpus))]\n",
    "term_doc_table = pd.DataFrame(term_document_matrix, index=indexes, columns=cols)\n",
    "\n",
    "print(term_doc_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-Idf Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             about_coep.txt  coep_cutoff.txt  placements.txt\n",
      "great              0.000000         0.000000        0.219857\n",
      "obc                0.000000         0.194921        0.000000\n",
      "147                0.000000         0.194921        0.000000\n",
      "2020               0.000000         0.071939        0.081143\n",
      "year               0.228366         0.000000        0.000000\n",
      "one                0.228366         0.000000        0.000000\n",
      "oldest             0.228366         0.000000        0.000000\n",
      "entrance           0.000000         0.194921        0.000000\n",
      "exam               0.000000         0.308942        0.000000\n",
      "133                0.000000         0.194921        0.000000\n",
      "87                 0.000000         0.194921        0.000000\n",
      "minor              0.000000         0.000000        0.219857\n",
      "college            0.361951         0.000000        0.000000\n",
      "opt                0.000000         0.000000        0.219857\n",
      "admission          0.000000         0.194921        0.000000\n",
      "mht                0.000000         0.194921        0.000000\n",
      "sc                 0.000000         0.194921        0.000000\n",
      "get                0.000000         0.000000        0.219857\n",
      "locate             0.228366         0.000000        0.000000\n",
      "ug                 0.000000         0.194921        0.000000\n",
      "cut                0.000000         0.194921        0.000000\n",
      "maharashtra        0.084283         0.114021        0.000000\n",
      "mhtcet             0.000000         0.194921        0.000000\n",
      "nt1                0.000000         0.194921        0.000000\n",
      "pune               0.361951         0.000000        0.000000\n",
      "maximum            0.000000         0.000000        0.219857\n",
      "course             0.000000         0.000000        0.219857\n",
      "opportunity        0.000000         0.000000        0.219857\n",
      "cet                0.000000         0.194921        0.000000\n",
      "163                0.000000         0.194921        0.000000\n",
      "depend             0.000000         0.194921        0.000000\n",
      "engineering        0.133585         0.071939        0.000000\n",
      "score              0.000000         0.194921        0.000000\n",
      "batch              0.000000         0.000000        0.219857\n",
      "computer           0.000000         0.000000        0.348466\n",
      "reservation        0.000000         0.194921        0.000000\n",
      "coep               0.084283         0.143879        0.000000\n",
      "india              0.361951         0.000000        0.000000\n",
      "1854               0.361951         0.000000        0.000000\n",
      "dte                0.000000         0.194921        0.000000\n",
      "civil              0.000000         0.194921        0.000000\n",
      "placement          0.000000         0.000000        0.510493\n",
      "establish          0.361951         0.000000        0.000000\n",
      "institute          0.228366         0.000000        0.000000\n",
      "conduct            0.000000         0.071939        0.081143\n",
      "50                 0.000000         0.000000        0.219857\n",
      "student            0.000000         0.000000        0.348466\n",
      "st                 0.000000         0.194921        0.000000\n",
      "cutoff             0.000000         0.308942        0.000000\n",
      "autonomous         0.228366         0.000000        0.000000\n",
      "along              0.000000         0.000000        0.219857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "N = len(corpus)\n",
    "\n",
    "log_tf = np.zeros((len(indexes), len(corpus)))\n",
    "for i in range(len(indexes)) :\n",
    "    for j in range(len(corpus)) :\n",
    "        log_tf[i] = np.log10(1+ term_document_matrix[i])\n",
    "\n",
    "log_df = np.zeros((len(indexes), len(corpus)))\n",
    "df_dict = {}\n",
    "for i in range(len(indexes)) :\n",
    "    df = np.count_nonzero(term_document_matrix[i])\n",
    "    #print(indexes[i], term_document_matrix[i], df)\n",
    "    df = np.log10(N/df)\n",
    "    df_dict[indexes[i]] = df\n",
    "    log_df[i] = [df]*N\n",
    "\n",
    "\n",
    "tf_idf = np.multiply(log_tf, log_df)\n",
    "tf_idf = normalize(tf_idf, axis=0, norm='l2')\n",
    "\n",
    "table = pd.DataFrame(tf_idf, index=indexes, columns=cols)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bihar\n"
     ]
    }
   ],
   "source": [
    "query = input()\n",
    "query = remove_punctuation(query).lower()\n",
    "query = remove_stopwords(query.split())\n",
    "query = lemmatize(query)\n",
    "\n",
    "query_tf = {}\n",
    "for term in query :\n",
    "    if term not in query_tf :\n",
    "        query_tf[term] = 1\n",
    "    else :\n",
    "        query_tf[term] += 1\n",
    "        \n",
    "query = set(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making query vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tf = np.zeros((len(indexes), 1))\n",
    "df = np.zeros((len(indexes), 1))\n",
    "common_terms = query.intersection(indexes)\n",
    "print(common_terms)\n",
    "if(common_terms) :\n",
    "    for term in common_terms :\n",
    "        tf[indexes_dict[term]][0] = query_tf[term]\n",
    "        df[indexes_dict[term]][0] = df_dict[term]\n",
    "log_tf = np.log10(1+tf)\n",
    "log_df = df\n",
    "tf_idf_query = np.multiply(log_tf, log_df)\n",
    "#print(tf_idf_query)\n",
    "tf_idf_query = normalize(tf_idf_query, axis=0, norm='l2')\n",
    "\n",
    "print(tf_idf_query.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity to find relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0. 0. 0.]\n",
      "Ranks: [2 1 0]\n",
      "Order of relevance :\n",
      "placements.txt coep_cutoff.txt about_coep.txt "
     ]
    }
   ],
   "source": [
    "scores = np.array([0]*len(corpus))\n",
    "\n",
    "scores = np.sum(tf_idf * tf_idf_query, axis = 0)\n",
    "\n",
    "ranks = np.argsort(scores)[::-1]\n",
    "print(\"Scores:\",scores)\n",
    "print(\"Ranks:\",ranks)\n",
    "\n",
    "print(\"Order of relevance :\")\n",
    "\n",
    "for i in ranks :\n",
    "    print(corpus[i], end = \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
